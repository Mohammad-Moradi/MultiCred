{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Sm93v_NCsdiK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def read_labels():\n",
        "\n",
        "  path = \"Labeled Data\\\\Labels.txt\"\n",
        "  data = []\n",
        "  labels = {}\n",
        "\n",
        "  with open(path, \"r\") as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "  for line in data:\n",
        "    temp = line.split()\n",
        "    sublist = temp[2:11]\n",
        "    temp[10] = temp[10].replace(\"\\n\", \"\")\n",
        "    score = sum(float(i) for i in sublist)\n",
        "    labels[temp[0]] = score\n",
        "\n",
        "  return labels\n",
        "\n",
        "def class_assesment(scores, setting):\n",
        "\n",
        "  labels = []\n",
        "\n",
        "  if setting == 4:\n",
        "    class_instances = [0, 0, 0, 0]\n",
        "    for score in scores:\n",
        "      if score >= 75:\n",
        "        labels.append([0])\n",
        "        class_instances[0] += 1\n",
        "      elif score >= 50:\n",
        "        labels.append([1])\n",
        "        class_instances[1] += 1\n",
        "      elif score >= 25:\n",
        "        labels.append([2])\n",
        "        class_instances[2] += 1\n",
        "      else:\n",
        "        labels.append([3])\n",
        "        class_instances[3] += 1\n",
        "  elif setting == 6:\n",
        "    class_instances = [0, 0, 0, 0, 0, 0]\n",
        "    for score in scores:\n",
        "      if score >= 83.5:\n",
        "        labels.append([0])\n",
        "        class_instances[0] += 1\n",
        "      elif score >= 67:\n",
        "        labels.append([1])\n",
        "        class_instances[1] += 1\n",
        "      elif score >= 50.5:\n",
        "        labels.append([2])\n",
        "        class_instances[2] += 1\n",
        "      elif score >= 34:\n",
        "        labels.append([3])\n",
        "        class_instances[3] += 1\n",
        "      elif score >= 17.5:\n",
        "        labels.append([4])\n",
        "        class_instances[4] += 1\n",
        "      else:\n",
        "        labels.append([5])\n",
        "        class_instances[5] += 1\n",
        "  elif setting == 8:\n",
        "    class_instances = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    for score in scores:\n",
        "      if score >= 87.5:\n",
        "        labels.append([0])\n",
        "        class_instances[0] += 1\n",
        "      elif score >= 75:\n",
        "        labels.append([1])\n",
        "        class_instances[1] += 1\n",
        "      elif score >= 62.5:\n",
        "        labels.append([2])\n",
        "        class_instances[2] += 1\n",
        "      elif score >= 50:\n",
        "        labels.append([3])\n",
        "        class_instances[3] += 1\n",
        "      elif score >= 37.5:\n",
        "        labels.append([4])\n",
        "        class_instances[4] += 1\n",
        "      elif score >= 25:\n",
        "        labels.append([5])\n",
        "        class_instances[5] += 1\n",
        "      elif score >= 12.5:\n",
        "        labels.append([6])\n",
        "        class_instances[6] += 1\n",
        "      else:\n",
        "        labels.append([7])\n",
        "        class_instances[7] += 1\n",
        "  else:\n",
        "    class_instances = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    for score in scores:\n",
        "      if score >= 90:\n",
        "        labels.append([0])\n",
        "        class_instances[0] += 1\n",
        "      elif score >= 80:\n",
        "        labels.append([1])\n",
        "        class_instances[1] += 1\n",
        "      elif score >= 70:\n",
        "        labels.append([2])\n",
        "        class_instances[2] += 1\n",
        "      elif score >= 60:\n",
        "        labels.append([3])\n",
        "        class_instances[3] += 1\n",
        "      elif score >= 50:\n",
        "        labels.append([4])\n",
        "        class_instances[4] += 1\n",
        "      elif score >= 40:\n",
        "        labels.append([5])\n",
        "        class_instances[5] += 1\n",
        "      elif score >= 30:\n",
        "        labels.append([6])\n",
        "        class_instances[6] += 1\n",
        "      elif score >= 20:\n",
        "        labels.append([7])\n",
        "        class_instances[7] += 1\n",
        "      elif score >= 10:\n",
        "        labels.append([8])\n",
        "        class_instances[8] += 1\n",
        "      else:\n",
        "        labels.append([9])\n",
        "        class_instances[9] += 1\n",
        "\n",
        "\n",
        "  return labels, class_instances\n",
        "\n",
        "\n",
        "def read_profile_embedding():\n",
        "  with open(\"Non textual features\\\\profile_tweet_non_textual_embedding.json\", 'r') as f:\n",
        "    temp = json.load(f)\n",
        "    # temp = ast.literal_eval(temp)\n",
        "    embed = {x: v for x, v in temp.items()}\n",
        "    f.close()\n",
        "  return embed\n",
        "\n",
        "def read_mention_embedding():\n",
        "  with open(\"Textual features\\\\Mentions\\\\mentions.json\", 'r') as f:\n",
        "    temp = json.load(f)\n",
        "    # temp = ast.literal_eval(temp)\n",
        "    embed = {x: v for x, v in temp.items()}\n",
        "    f.close()\n",
        "  return embed\n",
        "\n",
        "def read_tweet_text_embedding():\n",
        "  with open(\"Textual features\\\\Tweets\\\\tweets_embeddings_compressed.json\", 'r') as f:\n",
        "    temp = json.load(f)\n",
        "    # temp = ast.literal_eval(temp)\n",
        "    embed = {x: v for x, v in temp.items()}\n",
        "    f.close()\n",
        "  return embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWLG0q1ysxpr",
        "outputId": "f3cae606-a576-490f-9de5-8f4122735f6d"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "embbedings = []\n",
        "\n",
        "labels = read_labels()\n",
        "\n",
        "prof_embed = read_profile_embedding()\n",
        "mention_embed = read_mention_embedding()\n",
        "tweet_embed = read_tweet_text_embedding()\n",
        "accounts = mention_embed.keys()\n",
        "\n",
        "a = set(mention_embed.keys()) - set(prof_embed.keys())\n",
        "\n",
        "for acc in accounts:\n",
        "  if acc != \"heavy.com\":\n",
        "\n",
        "    dic = {}\n",
        "    vec = []\n",
        "\n",
        "    vec_2 = tweet_embed[acc]\n",
        "\n",
        "    vec_3 = functools.reduce(operator.concat, mention_embed[acc])\n",
        "    if acc == \"meanshealth.com\":\n",
        "      acc = \"menshealth.com\"\n",
        "\n",
        "    vec_1 = prof_embed[acc]\n",
        "    score = labels[acc]\n",
        "    vec = vec_1 + vec_3 + vec_2\n",
        "    # vec = vec_1\n",
        "    # vec = vec_1 + vec_3\n",
        "\n",
        "    dic[\"name\"] = acc\n",
        "    dic[\"embedding\"] = vec\n",
        "    dic[\"score\"] = score\n",
        "    embbedings.append(dic)\n",
        "\n",
        "for datapoint in embbedings:\n",
        "  X.append(datapoint[\"embedding\"])\n",
        "  Y.append(datapoint[\"score\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MPwVeMqht5km"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "Y_class, instances = class_assesment(Y, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KgQHymcLvYY6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_ = min_max_scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lPKPOJTvIk9",
        "outputId": "f0120fe7-1395-4db3-be9a-f7f773676e4d"
      },
      "outputs": [],
      "source": [
        "if num_classes > 6:\n",
        "    smote = SMOTE(k_neighbors=3)\n",
        "else:\n",
        "    smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(X_, Y_class)\n",
        "print(f'Original dataset shape {len(Y_class)}')\n",
        "print(f'Resample dataset shape {len(y_smote)}')\n",
        "\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(x_smote), np.array(y_smote), test_size=0.2, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MAj8mUsIvsC6"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  hidden_layer_1 = 256\n",
        "  hidden_layer_2 = 256\n",
        "  hidden_layer_3 = 64\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(51,), name=\"input_layer\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(units=hidden_layer_1, kernel_initializer='he_normal', activation='relu', name=\"hidden_layer_1\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(units=hidden_layer_2, kernel_initializer='he_normal', activation='relu', name=\"hidden_layer_2\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(units=hidden_layer_3, activation='relu', name=\"hidden_layer_3\"),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eafqp2ZvwLtR",
        "outputId": "255c0e72-500a-484f-8348-c7c282c45695"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "opt_1 = keras.optimizers.Adagrad(learning_rate=0.1)\n",
        "opt_2 = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(optimizer=opt_2, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, verbose=3, restore_best_weights=True, mode='min')\n",
        "\n",
        "model.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=2000,\n",
        "          batch_size = 16,\n",
        "          validation_split=0.2,\n",
        "          shuffle=True,\n",
        "          callbacks=callback\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AJ_SOeVCGqA",
        "outputId": "c468dc16-aa27-4a31-afa9-7657bbacd31d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_test_pred, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C0vqE06_uN4",
        "outputId": "ef6cb9af-5b8b-4ec9-e202-f8037a9a0084"
      },
      "outputs": [],
      "source": [
        "num_itration = 10\n",
        "\n",
        "for i in range(num_itration):\n",
        "\n",
        "  model = get_model()\n",
        "  lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "      initial_learning_rate=1e-2,\n",
        "      decay_steps=10000,\n",
        "      decay_rate=0.9)\n",
        "\n",
        "  opt_1 = keras.optimizers.Adagrad(learning_rate=0.1)\n",
        "  opt_2 = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "  model.compile(optimizer=opt_2, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "  callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, verbose=3, restore_best_weights=True, mode='min')\n",
        "\n",
        "  model.fit(X_train,\n",
        "            y_train,\n",
        "            epochs=2000,\n",
        "            batch_size = 16,\n",
        "            validation_split=0.2,\n",
        "            shuffle=True,\n",
        "            callbacks=callback\n",
        "  )\n",
        "\n",
        "  y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "  \n",
        "  log = classification_report(y_test, y_test_pred, digits=4)\n",
        "\n",
        "  path = 'Classifier Results\\\\' + str(num_classes) + '_class.txt'\n",
        "\n",
        "  with open(path, \"a\") as f:\n",
        "    f.write(log)\n",
        "    f.write('\\n')\n",
        "  f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
